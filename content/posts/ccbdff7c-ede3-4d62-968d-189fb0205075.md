---
title: 11月未遂政变后，OpenAI内部仍分裂严重
date: 2024-05-30T04:00:05.985Z
description: Arguments over safety and Sam Altman’s leadership spill back into public domain as artificial intelligence start-up hit by resignations
tags: 
- companies
author: ft
---

[原文链接](https://ft.com/content/ccbdff7c-ede3-4d62-968d-189fb0205075)

11月未遂政变后，OpenAI内部仍分裂严重

# 摘要：
OpenAI 面临内部分歧和辞职，因为在倡导快速人工智能发展的人与优先考虑安全的人之间存在紧张关系。这场争议源于11月份针对首席执行官萨姆·奥尔特曼（Sam Altman）的政变企图，这导致他被董事会暂时撤职。最近的离职人员包括联合创始人伊利亚·苏茨凯弗（Ilya Sutskever）和前 OpenAI 董事会成员海伦·托纳（Helen Toner），她批评了奥尔特曼在安全流程方面的领导力。该公司正在准备推出新的 AI 软件生成器，同时讨论为扩张筹集资金。

# 内部分歧：
OpenAI 在那些支持快速发展的人与强调人工通用智能（AGI）潜在风险而强调谨慎的人之间继续存在内部分歧。这些紧张关系导致了包括联合创始人伊利亚·苏茨凯弗（Ilya Sutskever）在内的几位知名人士的辞职。分歧源于对 OpenAI 商业化重点及其对 AGI 开发安全措施的影响的担忧。

# 联合创始人的辞职：
联合创始人伊利亚·苏茨凯弗（Ilya Sutskever）最近离职，突显了 OpenAI 内部的分歧，因为他因与首席执行官萨姆·奥尔特曼（Sam Altman）在人工智能安全和商业化方法上的分歧而离职。这次辞职前，11 月份曾发生过一次针对奥尔特曼的政变企图，导致他被董事会暂时撤职。

# 安全问题：
OpenAI 内部分歧的根源在于人们对该公司贪婪和 AGI 开发安全措施的担忧。一些员工担心匆忙创造超级智能可能会导致不可控制的后果，而其他人则优先考虑商业化和快速增长。伊利亚·苏茨凯弗（Ilya Sutskever）和海伦·托纳（Helen Toner）等关键人物的最近辞职突显了解决 OpenAI 领导结构中这些安全问题的重要性。

# 问题：
1. OpenAI 内部的分歧如何影响了其人工智能开发方法，尤其是与人工通用智能（AGI）相关的方法？
2. 导致伊利亚·苏茨凯弗（Ilya Sutskever）从 OpenAI 辞职的具体分歧是什么？
3. 围绕萨姆·奥尔特曼（Sam Altman）领导力的争议如何影响了 OpenAI 的声誉及其与投资者和决策者等外部利益相关者的关系？
4. OpenAI 可能以何种方式解决其内部分歧，以确保在快速人工智能开发和 AGI 安全措施之间采取平衡方法？
5. 来自微软或其他支持者等外部因素的压力如何加剧了 OpenAI 领导团队内部的紧张关系？

---

**Summary:** 
OpenAI faces internal divisions and resignations as tensions persist between those advocating for rapid AI development and others prioritizing safety. The controversy stems from a November coup attempt against CEO Sam Altman, which led to his temporary removal by the board. Recent high-profile departures include co-founder Ilya Sutskever and Helen Toner, former OpenAI board member who criticized Altman's leadership on safety processes. The company is preparing to launch a new AI software generation while discussing capital raising for expansion.

**Internal Divisions:** 
OpenAI continues to experience internal divisions between those favoring rapid development and others emphasizing caution in the face of potential risks associated with artificial general intelligence (AGI). These tensions have led to several high-profile resignations, including co-founder Ilya Sutskever. The disagreements stem from concerns about OpenAI's focus on commercialization and its impact on safety measures for AGI development.

**Resignation of Co-Founders:** 
The recent departure of co-founder Ilya Sutskever highlights the internal divisions within OpenAI, as he left due to disagreements with CEO Sam Altman's approach to AI safety and commercialization. This resignation follows a previous coup attempt against Altman in November, which led to his temporary removal by the board of directors.

**Safety Concerns:** 
The internal divisions within OpenAI are rooted in concerns about the company'cupsidity and safety measures for AGI development. Some employees fear that rushing into creating a superintelligence could lead to uncontrollable consequences, while others prioritize commercialization and rapid growth. The recent resignations of key figures like Ilya Sutskever and Helen Toner underscore the importance of addressing these safety concerns within OpenAI's leadership structure.

**Questions:** 
1. How have internal divisions at OpenAI impacted its approach to AI development, particularly in relation to artificial general intelligence (AGI)?
2. What specific disagreements led to Ilya Sutskever's resignation from OpenAI?
3. In what ways has the controversy surrounding Sam Altman's leadership affected OpenAI's reputation and relationships with external stakeholders, such as investors and policymakers?
4. How might OpenAI address its internal divisions to ensure a balanced approach between rapid AI development and safety measures for AGI?
5. What role do external factors, such as pressure from Microsoft or other backers, play in exacerbating the tensions within OpenAI's leadership team?

[Source Link](https://ft.com/content/ccbdff7c-ede3-4d62-968d-189fb0205075)

