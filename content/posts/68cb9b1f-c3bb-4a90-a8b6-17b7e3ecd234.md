---
title: OpenAI联合创始人伊利亚·苏兹卡弗宣布成立竞争对手人工智能初创公司
date: 2024-06-19T21:16:51.379Z
description: Safe Superintelligence Inc to focus on safety and comes a month after star researcher quit the ChatGPT maker
tags: 
- companies
author: ft
---

[原文链接](https://ft.com/content/68cb9b1f-c3bb-4a90-a8b6-17b7e3ecd234)

OpenAI联合创始人伊利亚·苏兹卡弗宣布成立竞争对手人工智能初创公司

# 安全超智能公司（SSI）成立，专注于打造安全的超智能系统

**新闻摘要：**
OpenAI联合创始人Ilya Sutskever在离开OpenAI后一个月宣布成立Safe Superintelligence Inc.（SSI），这是一家专注于开发安全超智能系统的初创公司。该公司由Sutskever与前OpenAI员工Daniel Levy和AI投资人/企业家Danial Gross共同创立。

**要点：**
- **安全超智能公司（SSI）** 的目标是创造超越人类认知能力的**安全超智能系统**，不受商业压力或管理层干扰和产品周期的干扰。
- SSI总部位于帕罗奥图和特拉维夫，联合创始人包括**Ilya Sutskever**（前OpenAI联合创始人）、**Daniel Levy**（前OpenAI员工）和**Danial Gross**（AI投资人/企业家）。
- 该公司专注于开发安全超智能系统，不受短期商业压力的影响。
- Sutskever在OpenAI的生成式AI进步中发挥了重要作用，由于对领导方向和安全问题的分歧而离开了该组织。
- 其他值得注意的离职包括**Jan Leike**（加入专注于安全AI系统的AI初创公司Anthropic）。

这篇文章介绍了人工智能领域的一项新创业：OpenAI联合创始人兼世界顶尖AI研究人员Ilya Sutskever宣布离开该公司，创立Safe Superintelligence Inc.（SSI）。这家初创公司致力于开发超越人类认知能力的**安全超智能系统**。

在Sutskever离开OpenAI之前，该公司经历了一段动荡时期，双方因领导方向和安全问题存在分歧。Safe Superintelligence Inc.的联合创始人包括另一名前OpenAI员工Daniel Levy和AI投资人/企业家Danial Gross，他曾与GitHub、Instacart等公司合作。

Safe Superintelligence Inc.的使命是创造不受投资者收入需求或管理层干扰和产品周期干扰的安全超智能系统。该公司总部位于帕罗奥图和特拉维夫，专注于开发造福人类且不受短期商业压力影响的安全超智能系统。

文章还提到OpenAI员工离开并创立自己专注于创建“安全”AI系统的初创公司的趋势，例如Dario Amodei在2011年创立的Anthropic，以及Jan Leike从OpenAI加入Anthropic。

---

 **Article Summary:**
OpenAI co-founder Ilya Sutskever announces the launch of Safe Superintelligence Inc (SSI), an AI start-up focused on building safe superintelligence, a month after leaving OpenAI following leadership clashes. The new company is founded by Sutskever alongside former OpenAI employee Daniel Levy and AI investor/entreprebur Danial Gross in the US.

**Key Points:**
- **Safe Superintelligence Inc (SSI)** aims to create safe superintelligence, surpassing human cognitive abilities without commercial pressures or distractions from management overhead and product cycles.
- SSI is headquartered in Palo Alto and Tel Aviv, with co-founders including **Ilya Sutskever** (former OpenAI co-founder), **Daniel Levy** (ex-OpenAI employee), and **Danial Gross** (AI investor/entrepreneur).
- The company's sole focus is on developing safe superintelligence, insulated from short-term commercial pressures.
- Sutskever has previously played a significant role in OpenAI's generative AI advancements and left the organization after disagreements over leadership direction and safety concerns.
- Other notable departures include **Jan Leike** (who joined Anthropic, an AI start-up focused on safe AI systems).

The article highlights a new venture in the field of artificial intelligence as Ilya Sutskever, co-founder of OpenAI and one of the world's most respected AI researchers, announces his departure from the company to establish Safe Superintelligence Inc (SSI). This start-up is dedicated to developing safe superintelligence that surpasses human cognitive abilities.

The new venture comes amidst a period of turmoil at OpenAI, with Sutskever's exit following disagreements over leadership direction and safety concerns within the organization. The co-founders of Safe Superintelligence Inc include Daniel Levy, another former employee of OpenAI, and Danial Gross, an AI investor/entrepreneur who has worked with companies such as GitHub, Instacart, Perplexity.ai, Character.api, and CoreWeave.

Safe Superintelligence Inc's mission is to create a safe superintelligent system without being influenced by revenue demands from investors or distractions caused by management overhead and product cycles. The company will be headquartered in both Palo Alto and Tel Aviv, with its sole focus on developing safe superintelligence that benefits humanity while remaining insulated from short-term commercial pressures.

The article also notes the recent trend of OpenAI employees leaving to establish their own start-ups focused on creating "safe" AI systems, such as Anthropic founded by Dario Amodei in 2n11 and Jan Leike's departure from OpenAI to join Anthropic.

[Source Link](https://ft.com/content/68cb9b1f-c3bb-4a90-a8b6-17b7e3ecd234)

