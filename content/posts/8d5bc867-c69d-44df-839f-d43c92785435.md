---
title: DeepMind发现政治性深度伪造图像位居恶意人工智能应用榜首
date: 2024-06-25T04:00:52.851Z
description: Artificial intelligence is used more to create realistic but fake celebrity images than to assist cyber attacks, Google unit says
tags: 
- technology
author: ft
---

[原文链接](https://ft.com/content/8d5bc867-c69d-44df-839f-d43c92785435)

DeepMind发现政治性深度伪造图像位居恶意人工智能应用榜首

# 人工智能滥用：
谷歌 DeepMind 部门的首项研究揭示，人工智能（AI）最常见的恶意使用是创建逼真的假图片、视频和音频，即“深伪”。这些深伪模仿政治家和名人的形象。第二常见的滥用行为是利用文本工具（如聊天机器人）生成在线错误信息来歪曲事实。

# DeepMind 的研究发现：
该研究与谷歌 DeepMind 的 R&D 部门 Jigsaw 合作进行，发现这些行为者的首要目标是塑造或影响公众舆论（27% 的使用情况）。这引发了人们对深伪可能在全球选举中产生影响的担忧。最近的例子包括英国首相里希·苏纳克和其他世界领导人在 TikTok、X 和 Instagram 等社交媒体平台上出现的深伪视频。

# 对深伪的担忧：
人们普遍担心，受众可能无法识别这些假内容，这可能会影响即将举行的选举中的选民。来自艾伦·图灵研究所（The Alan Turing Institute）的阿迪·扬杰瓦（Ardi Janjeva）强调了 AI 生成的内容扭曲我们对社会政治现实的集体理解对民主构成的长期风险。

# 生成式 AI 工具和错误信息：
随着 OpenAI 的 ChatGPT 和谷歌的 Gemini 等生成式产品的使用越来越广泛，公司正在监控其工具创建的错误信息和其他有害内容的传播。今年 5 月，OpenAI 的研究揭示了与俄罗斯、中国、伊朗和以色列相关的行动利用其工具进行虚假信息宣传。

# 谷歌 DeepMind 和 Jigsaw 的研究：
该研究分析了 2023 年 1 月至 2024 年 3 月之间从社交媒体平台 X 和 Reddit，以及在线博客和媒体报道中观察到的约 200 起滥用事件。滥用的第二常见动机是通过创建深伪或生成假新闻文章等服务赚钱。

# 对 AI 公司的影响：
谷歌 DeepMind 的研究将影响其如何改进评估以测试模型的安全性，并希望这些发现将影响竞争对手和其他利益相关者对生成式 AI 滥用中体现的危害的看法。

---

 **Artificial Intelligence Misuse:**  
The first study by Google's DeepMind division reveals that the most common malicious use of artificial intelligence (AI) is creating realistic but fake images, videos, and audio known as "deepfakes." These deepfakes impersonate politicians and celebrities. The second highest misuse involves falsifying information using text-based tools like chatbots to generate online misinformation.

**DeepMind's Research Findings:**  
The research, conducted with Google DeepMind's R&D unit Jigsaw, found that the primary goal of these actors is shaping or influencing public opinion (27% of uses). This raises concerns about deepfakes potentially impacting elections globally. Recent examples include deepfakes of UK Prime Minister Rishi Sunak and other global leaders appearing on social media platforms like TikTok, X, and Instagram.

**Concerns Over Deepfakes:**  
There is widespread concern that audiences may not recognize these as fake content, which could sway voters in upcoming elections. Ardi Janjeva from The Alan Turing Institute highlighted the long-term risks to democracies posed by AI-generated content distorting our collective understanding of sociopolitical reality.

**Generative AI Tools and Misinformation:**  
As generative products like OpenAI's ChatGPT and Google's Gemini become more widely used, companies are monitoring the spread of misinformation and other harmful content created by their tools. In May, research from OpenAI revealed operations linked to Russia, China, Iran, and Israel using its tools for disinformation campaigns.

**Google DeepMind and Jigsaw's Research:**  
The study analyzed around 200 observed incidents of misuse between January 2023 and March 2024 from social media platforms X and Reddit, as well as online blogs and media reports. The second most common motivation behind misuse was making money through services like creating deepfakes or generating fake news articles.

**Implications for AI Companebies:**  
Google DeepMind's research will influence how it improves evaluations to test models for safety and hopes that the findings will affect how competitors and other stakeholders view manifesting harms in generative AI misuse.

[Source Link](https://ft.com/content/8d5bc867-c69d-44df-839f-d43c92785435)

