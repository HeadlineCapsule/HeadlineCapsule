---
title: OpenAI 更重视「光鲜产品」，牺牲安全考量，顶尖研究者离职抗议
date: 2024-05-17T19:37:40.361Z
description: Jan Leike’s exit from ChatGPT maker is the latest sign of internal divisions over technology’s development
tags: 
- technology
author: ft
---

[原文链接](https://ft.com/content/0d7a80b2-32d7-4b9a-8053-c770cd09c27b)

# OpenAI 更重视「光鲜产品」，牺牲安全考量，顶尖研究者离职抗议

OpenAI 顶尖安全领袖 **Jan Leike** 因该公司更重视产品开发而非安全措施而选择离职。Leike 原先领导着一项控制超级人工智能工具的努力，他表达了对 OpenAI 文化的担忧，声称 **「光鲜产品」** 已经优先于安全考量。他的离职，以及 **Ilya Sutskever**（安全聚焦的 **「超级对齐团队」** 的联合创始人兼联合负责人）的离职，暴露了该公司内部的分歧和日益紧张的关系。

Leike 的担忧围绕着控制和引导人工智能系统的必要性--这些系统比人类更聪明--以及分配给这项关键研究的不充足资源。他强调了人工智能技术迅速进步所带来的潜在风险，包括错误信息的传播和人工智能工具 **「失控」** 所带来的生存威胁。致力于确保其技术造福全人类的 OpenAI 中的 **「超级对齐团队」** 解散，引发了人们对其公司对安全和道德发展的承诺的质疑。

**Jan Leike**，OpenAI 顶尖安全专家，因公司决策层更倾向于追求产品的表面光鲜亮丽而牺牲安全考量，选择了离职抗议。Leike 原本领导一个旨在控制超级人工智能工具的团队，他公开表达了对 OpenAI 公司文化的担忧，直言 **安全问题一直被排在「光鲜产品」的后面**。他的离职，以及 OpenAI 另一位联合创始人 **Ilya Sutskever**（一个聚焦安全对齐的团队的联合负责人）的离职，暴露了该公司在对待人工智能安全问题上的内部分歧和日益紧张的气氛。

Leike 所担忧的核心问题是如何引导和控制这些比人类更聪明的人工智能系统，以及 OpenAI 在这一关键研究领域投入资源不足。他强调了人工智能技术迅速发展所带来的潜在风险，包括虚假信息的传播和人工智能工具 **失控** 所带来的生存威胁。原本致力于确保其人工智能技术造福全人类的超级对齐团队在 OpenAI 的解散，引发了外界对该公司安全和道德发展承诺的质疑。

---

# OpenAI put ‘shiny products’ over safety, departing top researcher says

**Jan Leike**, a top safety leader at OpenAI, left the company due to disagreements over the prioritization of product development over safety measures. Leike, who led efforts to control super-powerful AI tools, expressed concerns about OpenAI's culture, stating that **safety had taken a back seat to "shiny products"**. His departure, along with that of **Ilya Sutskever**, a co-founder and co-lead of the **safety-focused "superalignment team"**, has exposed internal divisions and growing tensions within the company. Leike's concerns center around the need to steer and control AI systems smarter than humans and the lack of resources allocated to this crucial research. He highlights the potential risks associated with the rapid advancement of AI technology, including the spread of disinformation and the existential threat of AI tools "going rogue." The disbandment of the superalignment team at OpenAI, which was dedicated to ensuring its technology benefits all humanity, raises questions about the company's commitment to safety and ethical development.

[Source Link](https://ft.com/content/0d7a80b2-32d7-4b9a-8053-c770cd09c27b)

